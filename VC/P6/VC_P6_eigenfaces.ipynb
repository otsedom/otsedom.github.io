{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga conjunto de datos\n",
    "\n",
    "Se proporciona la carpeta, a través de la variable folder, donde cada subcarpeta se corresponde con una clase. Cada clase contiene muestras en forma de imágenes jpg, todas del mismo tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODIFICAR INDICANDO RUTA EN TU EQUIPO TRAS DESCAGAR DATOS DEL CAMPUS\n",
    "folder = \"C:/Users/otsed/Desktop/Docencia/VC/DatabaseGender59x65\" #Portátil\n",
    "\n",
    "# Contador de número de clases del conjunto\n",
    "nclasses = 0\n",
    "# Contador de muestras por clase\n",
    "nperclass = []\n",
    "# Etiqueta de cada clase (nombre de la subcarpeta)\n",
    "classlabels = []\n",
    "# Inicializa estructuras de datos y sus correpondientes etiquetas\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Valor de resolución por defecto de matplotlib\n",
    "dpi = matplotlib.rcParams['figure.dpi']\n",
    "\n",
    "# Asume que en la ruta indicada hay una subcarpeta por clase\n",
    "for class_name in os.listdir(folder):\n",
    "    # Cada subcarpeta implica una clase más\n",
    "    nclasses += 1\n",
    "    # Inicialmente esta clase no tiene muestras\n",
    "    nsamples = 0\n",
    "\n",
    "    # Compone la ruta\n",
    "    class_folder = os.path.join(folder, class_name)\n",
    "    for file_name in os.listdir(class_folder):\n",
    "        # Asume imágenes en formato jpg\n",
    "        if file_name.endswith('.jpg'):\n",
    "            # Lee la imagen\n",
    "            image = cv2.imread (os.path.join(class_folder, file_name),)\n",
    "            \n",
    "            # Lugar para aplicar un RoI \n",
    "            # Ejemplo para la mitad superior\n",
    "            # image = image[0:int(height/2),:]\n",
    "            \n",
    "            # Extrae tamaños\n",
    "            height, width, depth = image.shape\n",
    "            # Convierte  grises\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Añade a X, previa conversión en vector\n",
    "            X.append(gray.reshape(height*width))\n",
    "            # Añade etiqueta numérica de la muestra\n",
    "            Y.append(nclasses-1)\n",
    "            # Muestra primera imagen de la clase\n",
    "            if nsamples == 0:\n",
    "                figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "                plt.figure(figsize=figsize)\n",
    "                plt.imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
    "                plt.show()\n",
    "  \n",
    "            #Incrementa el número de muestras\n",
    "            nsamples += 1\n",
    "    nperclass.append(nsamples)\n",
    "    classlabels.append(class_name)\n",
    "    \n",
    "#Convierte a numpy array X e Y\n",
    "X = np.array(X,dtype='float32')\n",
    "Y = np.array(Y,dtype='float64')\n",
    "\n",
    "# Muestra datos del conjunto leído\n",
    "# Depuración\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "# Obtiene número de muestras y características\n",
    "n_samples , n_features = X.shape\n",
    "# Obtiene nombres de las clases\n",
    "class_names = np.array(classlabels)\n",
    "n_classes = class_names.shape[0]\n",
    "\n",
    "print(\"Dataset info:\")\n",
    "print(\"# samples: %d\" % n_samples)\n",
    "print(\"# features: %d\" % n_features)\n",
    "print(\"# classes: %d\" % n_classes)\n",
    "print(\"classes %s\" % classlabels)\n",
    "print(\"samples per class %s\" % str(nperclass)[1:-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseña conjunto experimental 70/30\n",
    "\n",
    "Divide los datos en conjunto de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into a train (70%) and test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"# samples in training set %d\" % X_train.shape[0])\n",
    "print(\"# samples in test set %d\" % X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Píxeles como descriptores y KNN con distancia euclídea para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN utilizando píxeles \n",
    "print(\"KNN classifier based on pixels\\nTraining...\")\n",
    "t0 = time()\n",
    "# k = 5 \n",
    "model_px = KNeighborsClassifier(n_neighbors = 5) \n",
    "  \n",
    "# fdtraining of model \n",
    "model_px.fit(X_train, y_train) \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting...\")\n",
    "t0 = time()\n",
    "y_pred=model_px.predict(X_test)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Classification results:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(\"Precision:  %0.3f, Recall:  %0.3f\" % ( precision_score(y_test, y_pred),recall_score(y_test, y_pred) )) \n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de PCA (150 componentes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA on the training subset for n_comp components\n",
    "n_comp = 150\n",
    "print(\"PCA computation using %d components from %d faces...\"\n",
    "      % (n_comp, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca_n = PCA(n_components=n_comp, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces_n = pca_n.components_.reshape((n_comp, height, width))\n",
    "\n",
    "print(\"Projecting training and test on the eigenfaces orthonormal basis...\")\n",
    "t0 = time()\n",
    "X_train_pca_n = pca_n.transform(X_train)\n",
    "X_test_pca_n = pca_n.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "# Cara media\n",
    "plt.imshow(pca_n.mean_.reshape(height,width),            cmap=plt.cm.bone)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "for i in range(30):\n",
    "    ax = fig.add_subplot(3, 10, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(pca_n.components_[i].reshape(height,width),\n",
    "              cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA (150 componentes) como descriptores y KNN con distancia euclídea para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for k neighbors\n",
    "k = 5\n",
    "print(\"KNN (k=%d) classifier based on %d PCA components...\" % (k, n_comp) ) \n",
    "t0 = time()\n",
    "model_pca_n = KNeighborsClassifier(n_neighbors = k) \n",
    "  \n",
    "# fdtraining of model \n",
    "model_pca_n.fit(X_train_pca_n, y_train) \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting...\")\n",
    "t0 = time()\n",
    "y_pred=model_pca_n.predict(X_test_pca_n)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(\"Precision:  %0.3f, Recall:  %0.3f\" % ( precision_score(y_test, y_pred),recall_score(y_test, y_pred) )) \n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA (150 componentes) como descriptores y SVM para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a SVM classifier\n",
    "print(\"SVM training...\")\n",
    "t0 = time()\n",
    "parameters = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],}\n",
    "# Grid search across parameter range\n",
    "clf_pca_n = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced'), parameters, cv=5\n",
    ")\n",
    "clf_pca_n = clf_pca_n.fit(X_train_pca_n, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf_pca_n.best_estimator_)\n",
    "\n",
    "\n",
    "print(\"Predicting\")\n",
    "t0 = time()\n",
    "y_pred = clf_pca_n.predict(X_test_pca_n)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(\"Precision:  %0.3f, Recall:  %0.3f\" % ( precision_score(y_test, y_pred),recall_score(y_test, y_pred) )) \n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de PCA (95% de la varianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ompute PCA on the training subset for n_comp components\n",
    "print(\"PCA computation for .95 of the variance from %d faces...\"\n",
    "      % (X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca_95 = PCA(.85).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"%d components selected\" % (pca_95.n_components_ ))\n",
    "\n",
    "eigenfaces_95 = pca_95.components_.reshape((pca_95.n_components_ , height, width))\n",
    "\n",
    "print(\"Projecting training and test on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca_95 = pca_95.transform(X_train)\n",
    "X_test_pca_95 = pca_95.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA (95% varianza) como descriptores y KNN con distancia euclídea para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for k neighbors\n",
    "k = 5\n",
    "print(\"KNN (k=%d) classifier based on %d PCA components...\" % (k, pca_95.n_components_) ) \n",
    "t0 = time()\n",
    "model_pca_95 = KNeighborsClassifier(n_neighbors = k) \n",
    "  \n",
    "# fdtraining of model \n",
    "model_pca_95.fit(X_train_pca_95, y_train) \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting...\")\n",
    "t0 = time()\n",
    "y_pred=model_pca_95.predict(X_test_pca_95)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(\"Precision:  %0.3f, Recall:  %0.3f\" % ( precision_score(y_test, y_pred),recall_score(y_test, y_pred) )) \n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA (95% varianza) como descriptores y SVM para clasificación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM classifier\n",
    "# Data normalization according to training data before training\n",
    "print(\"Normalization...\")\n",
    "scaler = MinMaxScaler()\n",
    "train_X = scaler.fit_transform(X_train_pca_95)\n",
    "test_X = scaler.transform(X_test_pca_95)\n",
    "\n",
    "print(\"SVM training...\")\n",
    "t0 = time()\n",
    "parameters = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],}\n",
    "# Grid serach across parameter range\n",
    "clf_pca_95 = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced'), parameters, cv=5\n",
    ")\n",
    "clf_pca_95 = clf_pca_95.fit(train_X, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf_pca_95.best_estimator_)\n",
    "\n",
    "\n",
    "print(\"Predicting\")\n",
    "t0 = time()\n",
    "y_pred = clf_pca_95.predict(test_X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(\"Precision:  %0.3f, Recall:  %0.3f\" % ( precision_score(y_test, y_pred),recall_score(y_test, y_pred) )) \n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('FACES')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea3a1ee99ce326e593ddb52cd278556d527fcb6552c40e2a47b1efb9d0183637"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
