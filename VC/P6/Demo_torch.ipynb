{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El objetivo de este cuaderno es aprender los conceptos básicos de la programación de redes usando Torch a través de una pequeña demo de un clasificador con el conjunto de datos MNIST.\n",
    "\n",
    " [Link al dataset](https://github.com/teavanist/MNIST-JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Dataset: https://github.com/teavanist/MNIST-JPG\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código tendrá 5 partes bien diferenciadas:\n",
    "- Carga del *Dataset* y *Dataloaders*\n",
    "- Creación del modelo\n",
    "- Creación del *Training Loop*\n",
    "- Entrenamiento\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Vamos a crear una clase dataset propia\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class MNISTDataset(Dataset): # Heredamos de la clase dataset de pytorch\n",
    "    def __init__(self, root, transform=None,partition = 'Train'): # Constructor de la clase\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.partition = partition\n",
    "        assert self.partition in ['Train','Test'], 'Partition must be Train or Test'\n",
    "        self.paths = self.get_filepaths(root,partition)\n",
    "        \n",
    "        \n",
    "    def get_filepaths(self,root,partition): # Función que devuelve los paths de las imágenes\n",
    "        if partition == 'Train':\n",
    "            root = os.path.join(root,partition)\n",
    "            folders = os.listdir(root) # Lista con los nombres de los archivos\n",
    "            folders = [os.path.join(root,file) for file in folders] # Añadimos a los nombres de los ar archivos la ruta a la carpeta \n",
    "            images = []\n",
    "            for folder in folders:\n",
    "                files = os.listdir(folder)\n",
    "                files = [os.path.join(folder,file) for file in files]\n",
    "                images += files\n",
    "                \n",
    "            return images\n",
    "        if partition == 'Test':\n",
    "            root = os.path.join(root,partition)\n",
    "            folders = os.listdir(root) # Lista con los nombres de los archivos\n",
    "            folders = [os.path.join(root,file) for file in folders] # Añadimos a los nombres de los ar archivos la ruta a la carpeta \n",
    "            images = []\n",
    "            for folder in folders:\n",
    "                files = os.listdir(folder)\n",
    "                files = [os.path.join(folder,file) for file in files]\n",
    "                images += files\n",
    "        \n",
    "            return images\n",
    "        \n",
    "    def __len__(self): # Devuelve el número de elementos del dataset\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx): # Devuelve un elemento concreto del dataset\n",
    "        img_path = self.paths[idx]\n",
    "        # leemos la imagen. Solo tiene un canal\n",
    "        img = cv2.imread(img_path,0)\n",
    "        img = img/255.0\n",
    "    \n",
    "        # Para la label de cada imagen tendremos que extraerla del path, es el nombre de la carpeta que la contiene\n",
    "        \n",
    "        label = int(img_path.split('\\\\')[-2]) # Si estamos en linux cambiar '\\\\' por '/'\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r'C:\\Users\\jisal\\Desktop\\Practicas_VC\\Demo_TOrch\\Data'\n",
    "\n",
    "# Una vez definida la clase, crear el dataset es tan sencillo como instanciar la clase\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "    )\n",
    "\n",
    "train_dataset = MNISTDataset(path_root,partition='Train',transform=transforms)\n",
    "test_dataset = MNISTDataset(path_root,partition='Test',transform=transforms)\n",
    " \n",
    "# Podemos dividir el dataset de entrenamiento en train y validation1\n",
    "# Hallamos la longitud de los datasets de train y test\n",
    "val_partition = 0.1\n",
    "n_val = int(len(train_dataset)*val_partition)\n",
    "n_train = int(len(train_dataset)*(1-val_partition))\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [n_train,n_val])\n",
    "\n",
    "# Ahora construimos los dataloaders, que son los que se encargan de cargar los datos en el modelo\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True) # drop_last elimina los batches que no tienen el tamaño especificado\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "\n",
    "print('Longitud del dataset de entrenamiento:',len(train_dataset), 'Número de batches:',len(train_loader))\n",
    "print('Longitud del dataset de validación:',len(val_dataset), 'Número de batches:',len(val_loader))\n",
    "print('Longitud del dataset de test:',len(test_dataset), 'Número de batches:',len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for x,y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    # vamos a mostrar 3 imágenes para asegurar que hemos cargado correctamente los datos\n",
    "    fig, axs = plt.subplots(1,3)\n",
    "\n",
    "    for i in range(3):\n",
    "        # Transform the tensor to numpy\n",
    "        image = np.array(x[i])\n",
    "        image = np.reshape(image, (image.shape[1], image.shape[2])) # Eliminamos el canal para mostrar bien la imagen\n",
    "        axs[i].imshow(image, cmap='gray')\n",
    "        axs[i].set_title(y[i].numpy())\n",
    "        axs[i].axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "        # Constructor de la clase\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        self.covs = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "        nn.Linear(in_features=64*5*5, out_features=128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=128, out_features=10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # reshape the input tensor to the correct shape\n",
    "        x = x.float() # A torch le gustan los floats, no los doubles que eran antes\n",
    "        x = x.view(x.size(0),1,28,28) # BxCxHxW\n",
    "        x = self.covs(x)\n",
    "        x = x.view(x.size(0),-1) # flatten\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "model = CNN().to(device) # ahora declaramos el modelo. Lo pasamos a la GPU sin está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a comprobar que el modelo funciona correctamente\n",
    "for patch in train_loader:\n",
    "    x, y = patch\n",
    "    print('Input shape:',x.shape)\n",
    "    print('Output shape:',model(x).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "def trainin_loop(model,train_loader,val_loader,epochs = 10,loss_fcn =  nn.CrossEntropyLoss(),optimizer=optim.SGD(model.parameters(),lr=1e-3)):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        val_loss = 0\n",
    "        training_loss = 0\n",
    "        \n",
    "        model.train() # modo entrenamiento        \n",
    "        for x,y in tqdm(train_loader):\n",
    "            \n",
    "            x = x.to(device) # importante enviar los datos al dispositivo\n",
    "            \n",
    "            optimizer.zero_grad() # reiniciamos los gradientes\n",
    "            y_pred = model(x) # realizamos la predicción con el modelo\n",
    "            loss = loss_fcn(y_pred,y) # Calculamos la pérdida\n",
    "            loss.backward() # Propagamos los gradientes por la red\n",
    "            optimizer.step() # Actualizamos los pesos\n",
    "            training_loss += loss.item()\n",
    "            \n",
    "        model.eval() # modo evaluación\n",
    "        for x,y in tqdm(val_loader):\n",
    "            x = x.to(device)\n",
    "            \n",
    "            \n",
    "            y_pred = model(x)\n",
    "            val_loss += loss_fcn(y_pred,y).item()\n",
    "\n",
    "        print('Epoch:',epoch, 'Training loss:',training_loss/len(train_loader), 'Validation loss:',val_loss/len(val_loader))\n",
    "        \n",
    "    print('Training finished')\n",
    "\n",
    "trainin_loop(model,train_loader,val_loader,epochs=5)\n",
    "\n",
    "# save model \n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model (model,test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,y in tqdm(test_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "    print('Accuracy:',100*correct/total)\n",
    "    \n",
    "eval_model(model,test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
