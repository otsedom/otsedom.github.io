{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4442edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd4a50",
   "metadata": {},
   "source": [
    "# Process image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frank-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./faces\n",
      "age_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/age_model_weights.h5\n",
      "To: D:\\RUNNERS\\code\\DeepFace\\.deepface\\weights\\age_model_weights.h5\n",
      "100%|██████████| 539M/539M [02:24<00:00, 3.74MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n",
      "To: D:\\RUNNERS\\code\\DeepFace\\.deepface\\weights\\gender_model_weights.h5\n",
      "100%|██████████| 537M/537M [02:57<00:00, 3.03MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_model_single_batch.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/race_model_single_batch.h5\n",
      "To: D:\\RUNNERS\\code\\DeepFace\\.deepface\\weights\\race_model_single_batch.h5\n",
      "100%|██████████| 537M/537M [02:32<00:00, 3.52MB/s] \n",
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:12<00:37, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:22<00:22, 11.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 9s 9s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:31<00:10, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:40<00:00, 10.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy.jpg\n",
      "{'x': 114, 'y': 92, 'w': 172, 'h': 172}\n",
      "33\n",
      "Man\n",
      "{'asian': 0.21307396236807108, 'indian': 0.1861895900219679, 'black': 0.013073140871711075, 'white': 67.57245659828186, 'middle eastern': 9.647394716739655, 'latino hispanic': 22.36781418323517}\n",
      "white\n",
      "{'angry': 3.2807939698287214e-08, 'disgust': 3.0905595090119024e-17, 'fear': 1.8165925190513854e-14, 'happy': 99.99972581863403, 'sad': 1.071018382488298e-10, 'surprise': 1.4111398681515563e-09, 'neutral': 0.00027434264211478876}\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "folder = './faces'\n",
    "\n",
    "print(folder)\n",
    "\n",
    "for file_name in os.listdir(folder):\n",
    "    # Asume imágenes en formato png o jpg\n",
    "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "        # Procesa la imagen que asume hay cara, no fuerza la detección\n",
    "        obj = DeepFace.analyze(img_path = os.path.join(folder, file_name), enforce_detection=False, actions =['age', 'gender', 'race', 'emotion'])\n",
    "        print(file_name)\n",
    "        print(obj[\"region\"])\n",
    "        print(obj[\"age\"])      \n",
    "        print(obj[\"gender\"])      \n",
    "        print(obj[\"race\"])       \n",
    "        print(obj[\"dominant_race\"]) \n",
    "        print(obj[\"emotion\"])\n",
    "        print(obj[\"dominant_emotion\"])\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1843aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "12028effb1af0cd2244438ff9b17d06bb1d7695ec7a554a144e43ec4b8b79006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
