{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga imagen y convierte a RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga imagen ejemplo con monedas\n",
    "img = cv2.imread('Monedas.jpg') \n",
    "print(img.shape)\n",
    "#Recordar que OpenCV lee las imágenes en BGR, por lo que convertimos para visualizr a RGB\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte a gris y muestra histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierte la imagen a todos de gris, mostrando el resultado\n",
    "img_gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Cálculo del histograma con 256 bins de una imagen en escala de grises\n",
    "hist = cv2.calcHist([img_gris], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_gris, cmap='gray')\n",
    "\n",
    "# Histograma sin normalizar\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Histograma\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# píxeles\")\n",
    "plt.plot(hist)\n",
    "plt.xlim([0, 256])\n",
    "# Separo subplots horizontalmente\n",
    "plt.subplots_adjust(wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta elementos tras umbralizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dos variantes de umbralizado. Probar otros parámetros, aplicar filtro previo, etc.\n",
    "umbral = 200 # Prueba varios comenzando en 130\n",
    "# Umbralizado binario invertido, dado que por defecto se asume objetos en blanco\n",
    "th1,img_th1 = cv2.threshold(img_gris,umbral,255,cv2.THRESH_BINARY_INV)\n",
    "print('Umbral fijo usado ', th1)\n",
    "# Umbralizado con método de Otsu para selección automática del umbral\n",
    "th2,img_th2 = cv2.threshold(img_gris,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "print('Umbral Otsu ', th2)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_gris,cmap='gray') \n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_th1,cmap='gray') \n",
    "plt.title('FIJO invertida')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_th2,cmap='gray') \n",
    "plt.title('OTSU invertida')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búsqueda de componentes y sus contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localiza contornos en imagen obtenida con umbral fijo\n",
    "#findContours está diseñada para imágenes con  figura en blanco y fondo negro\n",
    "#La imagen de entrada debe ser de un canal y 8 bits excepto en los modos RETR_CCOMP o RETR_FLOODFILL\n",
    "#hierarchy contiene información sobre el nivel del contorno, relaciones paterno-filiales (contornos contenidos en otros)\n",
    "\n",
    "#Obtiene todos los contornos: externos e internos\n",
    "contornos, hierarchy = cv2.findContours(\n",
    "    img_th1, #imagen\n",
    "    cv2.RETR_TREE, #Modo de recuperación (lista, árbol, nivel superior)\n",
    "    cv2.CHAIN_APPROX_SIMPLE #Método de aproximación del contorno\n",
    "    )\n",
    "\n",
    "#Dibuja sobre la imagen de entrada los contornos en verde\n",
    "#Cada vez que quiere pintar convierte img para no tener restos\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(img_rgb, contornos, -1, (0,255,0), 3)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Todos los contornos')\n",
    "\n",
    "#Obtiene únicamente los contornos externos\n",
    "contornos2, hierarchy2 = cv2.findContours(img_th1, \n",
    "    cv2.RETR_EXTERNAL , \n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Dibuja sobre la imagen de entrada sólo contornos externos\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(img_rgb, contornos2, -1, (0,255,0), 3)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Externos')\n",
    "\n",
    "#Dibuja contornos externos rellenos en imagen vacía\n",
    "#Imagen negra\n",
    "img_cont = np.zeros(img_rgb.shape)\n",
    "#Recorre los contornos externos\n",
    "for c in contornos2:\n",
    "    #Área del contorno\n",
    "    area = cv2.contourArea(c)\n",
    "    #Área mínima (útil filtrar en ocasiones)\n",
    "    if area > 10:\n",
    "        #Perímetro del contorno\n",
    "        perimetro = cv2.arcLength(c,True)\n",
    "        #Contenedor alineado con ejes de la imagen\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        #Mínimo contenedor ajustado para el contorno\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        #Mínimo círculo que contiene al contorno\n",
    "        (cx,cy),radio = cv2.minEnclosingCircle(c)\n",
    "        #Elipse ajustada al contorno, exgigiendo un mínimo de puntos del contornos\n",
    "        if c.shape[0] > 5:\n",
    "            elipse = cv2.fitEllipse(c)\n",
    "            #Para determinadas tareas nos puede interesará mostrar los valores obtenidos del contorno\n",
    "            #print(area, perimetro, rect, cx,cy,radio, elipse)\n",
    "\n",
    "        #Dibuja los contornos\n",
    "        cv2.drawContours(img_cont, [c], -1, (255,255,255), -1)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_cont) \n",
    "plt.title('Externos rellenos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativa contando círculos utilizando la Transformada de Hough. La selección de parámetros puede ser \"divertida\", más [información](https://docs.opencv.org/4.x/da/d53/tutorial_py_houghcircles.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversión a gris\n",
    "gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#Suaviza imagen (elimina altas frecuencias)\n",
    "pimg = cv2.medianBlur(gris, 7)\n",
    "#Localiza Círculos\n",
    "circ = cv2.HoughCircles(\n",
    "        pimg,  # imagen \n",
    "        cv2.HOUGH_GRADIENT,  # tipo de detección\n",
    "        1,\n",
    "        100,  # distancia mínima entre círculos\n",
    "        param1=100, # valor del gradiente\n",
    "        param2=50, # umbral acumulador\n",
    "        minRadius=50,  # radio mínimo\n",
    "        maxRadius=150,  # radio máximo\n",
    "    )\n",
    "\n",
    "#Dibuja sobre entrada e imagen vacía\n",
    "img_cont = np.zeros(img_rgb.shape)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "for det in circ[0]:\n",
    "        x_coor, y_coor, det_radio = det\n",
    "        cv2.circle(img_rgb,(int(x_coor), int(y_coor)),\n",
    "            int(det_radio),(0, 255, 0), 2)\n",
    "        cv2.circle(img_cont,(int(x_coor), int(y_coor)),\n",
    "            int(det_radio),(255, 255, 255), -1)\n",
    "\n",
    "#Muestra resultado\n",
    "plt.subplot(121)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Círculos')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_cont) \n",
    "plt.title('Rellenos')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las formas localizadas tienen distintas características geométricas, que pueden estimarse a partir de sus contornos. Más infromatión en la [documentación de OpenCV](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de polígono regular\n",
    "def poligono_regular(image, ctr, radio, lados, color):\n",
    "    pts = []\n",
    "    ang_step = 2 * np.pi / lados\n",
    "    for i in range(lados):\n",
    "        ang = i * ang_step\n",
    "        x = int(ctr[0] + radio * np.cos(ang))\n",
    "        y = int(ctr[1] + radio * np.sin(ang))\n",
    "        pts.append((x, y))\n",
    "    pts = np.array(pts, np.int32)\n",
    "    #regorganiza\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    cv2.fillPoly(image, [pts], color=color)\n",
    "\n",
    "# Imagen vacía\n",
    "img = np.zeros((400, 400, 1), dtype=\"uint8\")\n",
    "color = (255, 255, 255)\n",
    "\n",
    "# Formas básicas\n",
    "cv2.circle(img, (100, 100), 50, color, -1)  # Circular\n",
    "poligono_regular(img, (250, 150), 50, 5, color)  # Polígono regular\n",
    "cv2.ellipse(img, (200, 300), (100, 40), 0, 0, 360, color, -1)  # Elíptica\n",
    "\n",
    "# Localiza contornos\n",
    "contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Parámeros texto\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.3\n",
    "thickness = 1\n",
    "\n",
    "# Process each contour to calculate compactness and ellipse ratio (if possible)\n",
    "for c in contours:\n",
    "    # Puntos del contorno\n",
    "    clon = len(c)\n",
    "\n",
    "    # Área y perímetro\n",
    "    area = cv2.contourArea(c)\n",
    "    perimetro = cv2.arcLength(c, True)\n",
    "\n",
    "    #Contenedor alineado con ejes de la imagen\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    \n",
    "    # Compactness: 4*pi*Area/Perimeter^2\n",
    "    if perimetro > 0:\n",
    "        compacidad = (perimetro ** 2) / area\n",
    "    else:\n",
    "        compactness = 0\n",
    "    \n",
    "    # Ajusta elipse si hay suficientes puntos\n",
    "    if clon >= 5:\n",
    "        elipse = cv2.fitEllipse(c)\n",
    "        (center, axes, orientation) = elipse\n",
    "        major_axis = max(axes)\n",
    "        minor_axis = min(axes)\n",
    "        elipse_ratio = major_axis / minor_axis\n",
    "    else:\n",
    "        elipse_ratio = None\n",
    "    \n",
    "    # Muestra valores en imageb\n",
    "    cv2.putText(img, f\"n: {clon:.1f}\", (x, int(y+h+10)), font, font_scale, (255, 255, 255), thickness)\n",
    "    cv2.putText(img, f\"A: {area:.1f}\", (x, int(y+h+20)), font, font_scale, (255, 255, 255), thickness)\n",
    "    cv2.putText(img, f\"P: {perimetro:.1f}\", (x, int(y+h+30)), font, font_scale, color, thickness)\n",
    "    cv2.putText(img, f\"C: {compacidad:.1f}\", (x, int(y+h+40)), font, font_scale, color, thickness)\n",
    "    cv2.putText(img, f\"ER: {elipse_ratio:.1f}\", (x, int(y+h+50)), font, font_scale, color, thickness)\n",
    "    \n",
    "# Visualiza la imagen\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Formas\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: Captura una o varias imágenes con monedas no solapadas. Tras visualizar la imagen, identifica de forma interactiva (por ejemplo haciendo clic en la imagen) una moneda de un valor determinado en la imagen (por ejemplo de 1€). Tras ello, la tarea se resuelve mostrando por pantalla el número de monedas y la cantidad de dinero presentes en la imagen. No hay restricciones sobre utilizar medidas geométricas o de color. ¿Qué problemas han observado?\n",
    "\n",
    "Nota: Para establecer la correspondencia entre píxeles y milímetros, comentar que la moneda de un euro tiene un diámetro de 23.25 mm. la de 50 céntimos de 24.35, la de 20 céntimos de 22.25, etc. \n",
    "\n",
    "Extras: Considerar que la imagen pueda contener objetos que no son monedas y/o haya solape entre las monedas. Demo en vivo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mundo real es muy variado, las imágenes no siempre se capturan con unas condiciones de iluminación tan buenas o controladas. Ejemplo con aplicación de variantes de umbralizados ofrecidas por OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga imagen directamente en grises\n",
    "imgorig = cv2.imread('MPs.jpg', cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "img = cv2.GaussianBlur(imgorig,(5,5),0)\n",
    "\n",
    "#Umbralizados\n",
    "ret,imth1 = cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
    "thotsu,imth2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "print('Umbral escogido ', thotsu)\n",
    "imth3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "imth4 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    " \n",
    "titles = ['Original', 'Fijo','Otsu th='+str(int(thotsu)),\n",
    "            'Adaptivo promedio', 'Adaptivo Gaussiano']\n",
    "images = [img, imth1, imth2, 255 - imth3, 255 - imth4]\n",
    " \n",
    "for i in range(5):\n",
    "    plt.subplot(2,5,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i], fontsize=7)\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "    #Obtiene únicamente los contornos externos\n",
    "    if i>0:\n",
    "        res,imth = cv2.threshold(images[i],120,255,cv2.THRESH_BINARY)\n",
    "        contornos, hierarchy= cv2.findContours(imth, \n",
    "        cv2.RETR_EXTERNAL , \n",
    "        cv2.CHAIN_APPROX_SIMPLE)  \n",
    "        img_cont = np.zeros(img.shape)\n",
    "        cv2.drawContours(img_cont, contornos, -1, (255,255,255), -1)  \n",
    "        plt.subplot(2,5,i+6),plt.imshow(img_cont,'gray')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación de microplásticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos tres subimágenes de cada uno de los tres tipos considerados (el alquitrán no es microplástico)\n",
    "imgF = cv2.imread('FRA.png') \n",
    "imgP = cv2.imread('PEL.png') \n",
    "imgT = cv2.imread('TAR.png') \n",
    "\n",
    "#Mostramos\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgF) \n",
    "plt.title('Fragmentos')\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgP) \n",
    "plt.title('Pellet')\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgT) \n",
    "plt.title('Alquitrán')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la siguiente tarea, descrita más abajo, es desarrollar tu propio clasificador basado únicamente en heurísticas desde características geométricas y/o de apariencia, para distinguir en las imágenes completas, las partículas de cada tipo, debiendo mostrar la bondad del clasificador haciendo uso de métricas para ello. La siguiente celda obtiene varias métricas para un conjunto de datos imaginario (y con etiquetas aleatorias). Si bien las trataremos con más detalle en teoría, muestro un repertorio de ellas, dando más peso a la matriz de confusión. La ejecución de la celda requiere instalar el paquete scikit-learn.\n",
    "\n",
    "¿Qué es una matriz de confusión?\n",
    "Se utiliza para mostrar el comportamiento de un clasificador para las distintas clases conocidas, se relacionan las etiquetas de las muestras anotadas frente a las predichas por el clasificador. Se busca una matriz diagonal, pero la perfección es infrecuente.\n",
    "\n",
    "El siguiente ejemplo, muestra el modo de obtener la matriz de confusión para un hipotético problema con cuatro clases, y valores de anotación (variable y) y predicción (variable y_pred) obtenidos de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "\n",
    "# Numero de muestras\n",
    "n = 100  \n",
    "nclases = 4\n",
    "\n",
    "# A falta de clasificador y conjunto de datos, creamos anotaciones y predicciones de forma aleatoria\n",
    "# Vector aleatorio con etiquetas anotadas\n",
    "y = [random.randint(0, nclases - 1) for _ in range(n)]\n",
    "print('Anotaciones ' , y)\n",
    "\n",
    "# Vector aleatorio con etiquetas predichas por un supuesto clasificador\n",
    "y_pred = [random.randint(0, nclases - 1) for _ in range(n)]\n",
    "print('Predicciones ' , y_pred)\n",
    "\n",
    "print('¿Cómo de bien encajan anotación y predicción?')\n",
    "\n",
    "#Cálculo de métricas\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "#Para más de una clase se define la forma de promediar\n",
    "precision = precision_score(y, y_pred,average='weighted')\n",
    "recall = recall_score(y, y_pred,average='weighted')\n",
    "f1score = f1_score(y, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy (TP/(n))= {accuracy}\")\n",
    "print(f\"Precision (TP/(TP+FP)) = {precision}\")\n",
    "print(f\"Recall (TP/(TP+FN)) = {recall}\")\n",
    "print(f\"F1 Score (2*(precision*recall)/(precision+recall)) = {f1score}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.set(font_scale = 1.75)#tamaños tipografía\n",
    "sns.set(font_scale = 3.0)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "        conf_matrix, # confusion matrix 2D array \n",
    "        annot=True, # Muestra números en las celdas\n",
    "        fmt='d', # valores enteros\n",
    "        cbar=False, # sin barra de colores\n",
    "        cmap='flag', # mapa de colores\n",
    "        #vmax=175 # contraste de color\n",
    "    )\n",
    "\n",
    "#Etiquetas matriz de confusión\n",
    "label_font = {'size':'25'}\n",
    "ax.set_xlabel(\"Predicha\", labelpad=-0.75, fontdict=label_font)\n",
    "ax.set_ylabel(\"Real/Anotado\", labelpad=20, fontdict=label_font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: Las tres imágenes cargadas en la celda inicial, han sido extraidas de las imágenes de mayor tamaño presentes en la carpeta. La tarea consiste en extraer características (geométricas y/o visuales) e identificar patrones que permitan distinguir las partículas de cada una de las tres clases, evaluando los aciertos y fallos con las imágenes completas considerando las métricas mostradas y la matriz de confusión. La matriz de confusión, muestra para cada clase el número de muestras que se clasifican correctamente de dicha clase, y el número de muestras que se clasifican incorrectamente por cada una de las otras dos clases.\n",
    "\n",
    "En el trabajo [SMACC: A System for Microplastics Automatic Counting and Classification](https://doi.org/10.1109/ACCESS.2020.2970498), las características geométricas utilizadas fueron:\n",
    "\n",
    "- Área en píxeles\n",
    "- Perímetro en píxeles\n",
    "- Compacidad (relación entre el cuadrado del perímetro y el área de la partícula)\n",
    "- Relación del área de la partícula con la del contenedor\n",
    "- Relación del ancho y el alto del contenedor\n",
    "- Relación entre los ejes de la elipse ajustada\n",
    "- Definido el centroide, relación entre las distancias menor y mayor al contorno\n",
    "\n",
    "Si no se quedan satisfechos con la segmentación obtenida, es el mundo real, también en el README comento técnicas recientes de segmentación, que podrían despertar su curiosidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('FACES')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea3a1ee99ce326e593ddb52cd278556d527fcb6552c40e2a47b1efb9d0183637"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
