{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Identificación de monedas\n",
    "\n",
    "Carga imagen y convierte a RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga imagen ejemplo con monedas\n",
    "img = cv2.imread('Monedas.jpg') \n",
    "print(img.shape)\n",
    "#Recordar que OpenCV lee las imágenes en BGR, por lo que convertimos para visualizr a RGB\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte a gris y muestra histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierte la imagen a todos de gris, mostrando el resultado\n",
    "img_gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Cálculo del histograma con 256 bins de una imagen en escala de grises\n",
    "hist = cv2.calcHist([img_gris], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_gris, cmap='gray')\n",
    "\n",
    "# Histograma sin normalizar\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Histograma\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# píxeles\")\n",
    "plt.plot(hist)\n",
    "plt.xlim([0, 256])\n",
    "# Separo subplots horizontalmente\n",
    "plt.subplots_adjust(wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta resultado tras umbralizar (poniendo a negro el fondo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dos variantes de umbralizado. Probar otros parámetros, aplicar filtro previo, etc.\n",
    "umbral = 200 # Prueba varios comenzando en 130\n",
    "# Umbralizado binario invertido, dado que por defecto se asume objetos en blanco\n",
    "th1,img_th1 = cv2.threshold(img_gris,umbral,255,cv2.THRESH_BINARY_INV)\n",
    "print('Umbral fijo usado ', th1)\n",
    "# Umbralizado con método de Otsu para selección automática del umbral\n",
    "th2,img_th2 = cv2.threshold(img_gris,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "print('Umbral Otsu ', th2)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_gris,cmap='gray') \n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_th1,cmap='gray') \n",
    "plt.title('FIJO invertida')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_th2,cmap='gray') \n",
    "plt.title('OTSU invertida')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búsqueda de componentes y sus contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localiza contornos en imagen obtenida con umbral fijo\n",
    "#findContours está diseñada para imágenes con  figura en blanco y fondo negro\n",
    "#La imagen de entrada debe ser de un canal y 8 bits excepto en los modos RETR_CCOMP o RETR_FLOODFILL\n",
    "#hierarchy contiene información sobre el nivel del contorno, relaciones paterno-filiales (contornos contenidos en otros)\n",
    "\n",
    "#Obtiene todos los contornos: externos e internos\n",
    "contornos, hierarchy = cv2.findContours(\n",
    "    img_th1, #imagen\n",
    "    cv2.RETR_TREE, #Modo de recuperación (lista, árbol, nivel superior)\n",
    "    cv2.CHAIN_APPROX_SIMPLE #Método de aproximación del contorno\n",
    "    )\n",
    "\n",
    "#Dibuja sobre la imagen de entrada los contornos en verde\n",
    "#Cada vez que quiere pintar convierte img para no tener restos\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(img_rgb, contornos, -1, (0,255,0), 3)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Todos los contornos')\n",
    "\n",
    "#Obtiene únicamente los contornos externos\n",
    "contornos2, hierarchy2 = cv2.findContours(img_th1, \n",
    "    cv2.RETR_EXTERNAL , \n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Dibuja sobre la imagen de entrada sólo contornos externos\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(img_rgb, contornos2, -1, (0,255,0), 3)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Externos')\n",
    "\n",
    "#Dibuja contornos externos rellenos en imagen vacía\n",
    "#Imagen negra\n",
    "img_cont = np.zeros(img_rgb.shape)\n",
    "#Recorre los contornos externos\n",
    "for c in contornos2:\n",
    "    #Área del contorno\n",
    "    area = cv2.contourArea(c)\n",
    "    #Área mínima (útil filtrar en ocasiones)\n",
    "    if area > 10:\n",
    "        #Perímetro del contorno\n",
    "        perimetro = cv2.arcLength(c,True)\n",
    "        #Contenedor alineado con ejes de la imagen\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        #Mínimo contenedor ajustado para el contorno\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        #Mínimo círculo que contiene al contorno\n",
    "        (cx,cy),radio = cv2.minEnclosingCircle(c)\n",
    "        #Elipse ajustada al contorno, exgigiendo un mínimo de puntos del contornos\n",
    "        if c.shape[0] > 5:\n",
    "            elipse = cv2.fitEllipse(c)\n",
    "            #Para determinadas tareas nos puede interesará mostrar los valores obtenidos del contorno\n",
    "            #print(area, perimetro, rect, cx,cy,radio, elipse)\n",
    "\n",
    "        #Dibuja los contornos\n",
    "        cv2.drawContours(img_cont, [c], -1, (255,255,255), -1)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_cont) \n",
    "plt.title('Externos rellenos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativa contando círculos utilizando la Transformada de Hough. La selección de parámetros puede ser \"divertida\", más [información](https://docs.opencv.org/4.x/da/d53/tutorial_py_houghcircles.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversión a gris\n",
    "gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#Suaviza imagen (elimina altas frecuencias)\n",
    "pimg = cv2.medianBlur(gris, 7)\n",
    "#Localiza Círculos\n",
    "circ = cv2.HoughCircles(\n",
    "        pimg,  # imagen \n",
    "        cv2.HOUGH_GRADIENT,  # tipo de detección\n",
    "        1,\n",
    "        100,  # distancia mínima entre círculos\n",
    "        param1=100, # valor del gradiente\n",
    "        param2=50, # umbral acumulador\n",
    "        minRadius=50,  # radio mínimo\n",
    "        maxRadius=150,  # radio máximo\n",
    "    )\n",
    "\n",
    "#Dibuja sobre entrada e imagen vacía\n",
    "img_cont = np.zeros(img_rgb.shape)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "for det in circ[0]:\n",
    "        x_coor, y_coor, det_radio = det\n",
    "        cv2.circle(img_rgb,(int(x_coor), int(y_coor)),\n",
    "            int(det_radio),(0, 255, 0), 2)\n",
    "        cv2.circle(img_cont,(int(x_coor), int(y_coor)),\n",
    "            int(det_radio),(255, 255, 255), -1)\n",
    "\n",
    "#Muestra resultado\n",
    "plt.subplot(121)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Círculos')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_cont) \n",
    "plt.title('Rellenos')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las formas localizadas tienen distintas características geométricas, que pueden estimarse a partir de sus contornos. Más información en la [documentación de OpenCV](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de polígono regular\n",
    "def poligono_regular(image, ctr, radio, lados, color):\n",
    "    pts = []\n",
    "    ang_step = 2 * np.pi / lados\n",
    "    for i in range(lados):\n",
    "        ang = i * ang_step\n",
    "        x = int(ctr[0] + radio * np.cos(ang))\n",
    "        y = int(ctr[1] + radio * np.sin(ang))\n",
    "        pts.append((x, y))\n",
    "    pts = np.array(pts, np.int32)\n",
    "    #regorganiza\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    cv2.fillPoly(image, [pts], color=color)\n",
    "\n",
    "# Imagen vacía\n",
    "img = np.zeros((400, 400, 1), dtype=\"uint8\")\n",
    "color = (255, 255, 255)\n",
    "\n",
    "# Formas básicas\n",
    "cv2.circle(img, (100, 100), 50, color, -1)  # Circular\n",
    "poligono_regular(img, (250, 150), 50, 5, color)  # Polígono regular\n",
    "cv2.ellipse(img, (200, 300), (100, 40), 0, 0, 360, color, -1)  # Elíptica\n",
    "\n",
    "# Localiza contornos\n",
    "contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Parámeros texto\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.3\n",
    "thickness = 1\n",
    "\n",
    "# Process each contour to calculate compactness and ellipse ratio (if possible)\n",
    "for c in contours:\n",
    "    # Puntos del contorno\n",
    "    clon = len(c)\n",
    "\n",
    "    # Área y perímetro\n",
    "    area = cv2.contourArea(c)\n",
    "    perimetro = cv2.arcLength(c, True)\n",
    "\n",
    "    #Contenedor alineado con ejes de la imagen\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    \n",
    "    # Compactness: 4*pi*Area/Perimeter^2\n",
    "    if perimetro > 0:\n",
    "        compacidad = (perimetro ** 2) / area\n",
    "    else:\n",
    "        compactness = 0\n",
    "    \n",
    "    # Ajusta elipse si hay suficientes puntos\n",
    "    if clon >= 5:\n",
    "        elipse = cv2.fitEllipse(c)\n",
    "        (center, axes, orientation) = elipse\n",
    "        major_axis = max(axes)\n",
    "        minor_axis = min(axes)\n",
    "        elipse_ratio = major_axis / minor_axis\n",
    "    else:\n",
    "        elipse_ratio = None\n",
    "    \n",
    "    # Muestra valores en imageb\n",
    "    cv2.putText(img, f\"n: {clon:.1f}\", (x, int(y+h+10)), font, font_scale, (255, 255, 255), thickness)\n",
    "    cv2.putText(img, f\"A: {area:.1f}\", (x, int(y+h+20)), font, font_scale, (255, 255, 255), thickness)\n",
    "    cv2.putText(img, f\"P: {perimetro:.1f}\", (x, int(y+h+30)), font, font_scale, color, thickness)\n",
    "    cv2.putText(img, f\"C: {compacidad:.1f}\", (x, int(y+h+40)), font, font_scale, color, thickness)\n",
    "    cv2.putText(img, f\"ER: {elipse_ratio:.1f}\", (x, int(y+h+50)), font, font_scale, color, thickness)\n",
    "    \n",
    "# Visualiza la imagen\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Formas\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: Los ejemplos ilustrativos anteriores permiten saber el número de monedas presentes en la imagen. ¿Cómo saber la cantidad de dinero presente en ella? Sugerimos identificar de forma interactiva (por ejemplo haciendo clic en la imagen) una moneda de un valor determinado en la imagen (por ejemplo de 1€). Tras obtener esa información y las dimensiones en milímetros de las distintas monedas, realiza una propuesta para estimar la cantidad de dinero en la imagen. Muestra la cuenta de monedas y dinero sobre la imagen. No hay restricciones sobre utilizar medidas geométricas o de color. \n",
    "\n",
    "Una vez resuelto el reto con la imagen ideal proporcionada, captura una o varias imágenes con monedas. Aplica el mismo esquema, tras identificar la moneda del valor determinado, calcula el dinero presente en la imagen. ¿Funciona correctamente? ¿Se observan problemas?\n",
    "\n",
    "Nota: Para establecer la correspondencia entre píxeles y milímetros, comentar que la moneda de un euro tiene un diámetro de 23.25 mm. la de 50 céntimos de 24.35, la de 20 céntimos de 22.25, etc. \n",
    "\n",
    "Extras: Considerar que la imagen pueda contener objetos que no son monedas y/o haya solape entre las monedas. Demo en vivo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Clasificación de microplásticos\n",
    "\n",
    "El mundo real es muy variado, las imágenes no siempre se capturan con unas condiciones de iluminación tan buenas o controladas. Ejemplo con aplicación de variantes de umbralizados ofrecidas por OpenCV sobre una imagen de muestras de microplásticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga imagen directamente en grises\n",
    "imgorig = cv2.imread('MPs_test.jpg', cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "img = cv2.GaussianBlur(imgorig,(5,5),0)\n",
    "\n",
    "#Umbralizados\n",
    "ret,imth1 = cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
    "thotsu,imth2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "print('Umbral escogido ', thotsu)\n",
    "imth3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "imth4 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    " \n",
    "titles = ['Original', 'Fijo','Otsu th='+str(int(thotsu)),\n",
    "            'Adaptivo promedio', 'Adaptivo Gaussiano']\n",
    "images = [img, imth1, imth2, 255 - imth3, 255 - imth4]\n",
    " \n",
    "for i in range(5):\n",
    "    plt.subplot(2,5,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i], fontsize=7)\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "    #Obtiene únicamente los contornos externos\n",
    "    if i>0:\n",
    "        res,imth = cv2.threshold(images[i],120,255,cv2.THRESH_BINARY)\n",
    "        contornos, hierarchy= cv2.findContours(imth, \n",
    "        cv2.RETR_EXTERNAL , \n",
    "        cv2.CHAIN_APPROX_SIMPLE)  \n",
    "        img_cont = np.zeros(img.shape)\n",
    "        cv2.drawContours(img_cont, contornos, -1, (255,255,255), -1)  \n",
    "        plt.subplot(2,5,i+6),plt.imshow(img_cont,'gray')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta imagen de muestras de microplásticos tenemos una anotación (que puede contener errores) de la tipología de las partículas. Esta será la imagen de test en los experimentos posteriores, no puedes hacer uso de esta imagen para entrenar tu clasificador, solo par evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagen y anotaciones\n",
    "imagen = \"MPs_test.jpg\"          # Imagen original\n",
    "csv_file = \"MPs_test_bbs.csv\"  # CSV con coordenadas y tipología\n",
    "\n",
    "# Colores de cada clase\n",
    "colores = {\n",
    "    \"FRA\": (0, 0, 255),   # Rojo \n",
    "    \"PEL\": (0, 255, 0),   # Verde\n",
    "    \"TAR\": (255, 0, 0)    # Azul\n",
    "}\n",
    "\n",
    "# Imagen\n",
    "img = cv2.imread(imagen)\n",
    "\n",
    "# Cara csv y dibujar rectángulos\n",
    "with open(csv_file, newline=\"\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        etiqueta = row[\"label\"]\n",
    "        x_min, y_min, x_max, y_max = map(int, [row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]])\n",
    "        \n",
    "        # Color según etiqueta\n",
    "        color = colores.get(etiqueta, (0, 0, 0))  # negro por defecto si no encuentra\n",
    "        \n",
    "        # Dibujar rectángulo\n",
    "        cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "        \n",
    "        # Etiqueta \n",
    "        cv2.putText(img, etiqueta, (x_min, y_min - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "# Visualiza resultado\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Anotaciones\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Muestras de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos tres subimágenes, por simplicidad, de cada uno de los tres tipos considerados (el alquitrán no es microplástico)\n",
    "imgF = cv2.imread('FRA.png') \n",
    "imgP = cv2.imread('PEL.png') \n",
    "imgT = cv2.imread('TAR.png') \n",
    "\n",
    "#Mostramos\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgF) \n",
    "plt.title('Fragmentos')\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgP) \n",
    "plt.title('Pellet')\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgT) \n",
    "plt.title('Alquitrán')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la siguiente tarea, descrita más abajo, es desarrollar tu propio clasificador basado únicamente en heurísticas basadas en características geométricas y/o de apariencia, a partir de las imágenes completas de las partículas de cada tipo, debiendo mostrar la bondad del clasificador haciendo uso de métricas para ello sobre las anotaciones de la imagen de test *MPs_test.png*. La siguiente celda obtiene varias métricas para un conjunto de datos imaginario (y con etiquetas aleatorias). Si bien las trataremos con más detalle en teoría, muestro un repertorio de ellas, dando más peso a la matriz de confusión. La ejecución de la celda requiere instalar el paquete scikit-learn.\n",
    "\n",
    "¿Qué es una matriz de confusión?\n",
    "Se utiliza para mostrar el comportamiento de un clasificador para las distintas clases conocidas, se relacionan las etiquetas de las muestras anotadas frente a las predichas por el clasificador. Se busca una matriz diagonal, pero la perfección es infrecuente.\n",
    "\n",
    "El siguiente ejemplo, muestra el modo de obtener la matriz de confusión para un hipotético problema con cuatro clases, y valores de anotación (variable y) y predicción (variable y_pred) obtenidos de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "\n",
    "# Numero de muestras\n",
    "n = 100  \n",
    "nclases = 4\n",
    "\n",
    "# A falta de clasificador y conjunto de datos, creamos anotaciones y predicciones de forma aleatoria\n",
    "# Vector aleatorio con etiquetas anotadas\n",
    "y = [random.randint(0, nclases - 1) for _ in range(n)]\n",
    "print('Anotaciones ' , y)\n",
    "\n",
    "# Vector aleatorio con etiquetas predichas por un supuesto clasificador\n",
    "y_pred = [random.randint(0, nclases - 1) for _ in range(n)]\n",
    "print('Predicciones ' , y_pred)\n",
    "\n",
    "print('¿Cómo de bien encajan anotación y predicción?')\n",
    "\n",
    "#Cálculo de métricas\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "#Para más de una clase se define la forma de promediar\n",
    "precision = precision_score(y, y_pred,average='weighted')\n",
    "recall = recall_score(y, y_pred,average='weighted')\n",
    "f1score = f1_score(y, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy (TP/(n))= {accuracy}\")\n",
    "print(f\"Precision (TP/(TP+FP)) = {precision}\")\n",
    "print(f\"Recall (TP/(TP+FN)) = {recall}\")\n",
    "print(f\"F1 Score (2*(precision*recall)/(precision+recall)) = {f1score}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.set(font_scale = 1.75)#tamaños tipografía\n",
    "sns.set(font_scale = 3.0)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "        conf_matrix, # confusion matrix 2D array \n",
    "        annot=True, # Muestra números en las celdas\n",
    "        fmt='d', # valores enteros\n",
    "        cbar=False, # sin barra de colores\n",
    "        cmap='flag', # mapa de colores\n",
    "        #vmax=175 # contraste de color\n",
    "    )\n",
    "\n",
    "#Etiquetas matriz de confusión\n",
    "label_font = {'size':'25'}\n",
    "ax.set_xlabel(\"Predicha\", labelpad=-0.75, fontdict=label_font)\n",
    "ax.set_ylabel(\"Real/Anotado\", labelpad=20, fontdict=label_font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: La tarea consiste en extraer características (geométricas y/o visuales) de las tres imágenes completas de partida, y *aprender* patrones que permitan identificar las partículas en nuevas imágenes. Para ello se proporciona como imagen de test *MPs_test.jpg* y sus correpondientes anotaciones *MPs_test_bbs.csv* con la que deben obtener las métricas para su propuesta de clasificación de microplásticos, además de la matriz de confusión. La matriz de confusión permitirá mostrar para cada clase el número de muestras que se clasifican correctamente de dicha clase, y el número de muestras que se clasifican incorrectamente como perteneciente a una de las otras dos clases.\n",
    "\n",
    "En el trabajo [SMACC: A System for Microplastics Automatic Counting and Classification](https://doi.org/10.1109/ACCESS.2020.2970498), las características geométricas utilizadas fueron:\n",
    "\n",
    "- Área en píxeles\n",
    "- Perímetro en píxeles\n",
    "- Compacidad (relación entre el cuadrado del perímetro y el área de la partícula)\n",
    "- Relación del área de la partícula con la del contenedor\n",
    "- Relación del ancho y el alto del contenedor\n",
    "- Relación entre los ejes de la elipse ajustada\n",
    "- Definido el centroide, relación entre las distancias menor y mayor al contorno\n",
    "\n",
    "Si no se quedan satisfechos con la segmentación obtenida, es el mundo real, también en el README comento técnicas recientes de segmentación, que podrían despertar su curiosidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
