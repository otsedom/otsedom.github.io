{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "pediatric-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "#from deepface.commons import functions\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-vulnerability",
   "metadata": {},
   "source": [
    "# Definición de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "criminal-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSVMPredictions(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "    print(\"SVM Normalization...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    train_X = scaler.fit_transform(X_train)\n",
    "    test_X = scaler.transform(X_test)\n",
    "\n",
    "    print(\"SVM training...\")\n",
    "    t0 = time()\n",
    "    parameters = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],}\n",
    "    # Grid serach across parameter range\n",
    "    clf = GridSearchCV(\n",
    "        SVC(kernel='rbf', class_weight='balanced'), parameters, cv=5\n",
    "    )\n",
    "    clf = clf.fit(train_X, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "\n",
    "\n",
    "    print(\"Predicting\")\n",
    "    t0 = time()\n",
    "    y_pred = clf.predict(test_X)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    return y_pred, y_test\n",
    "\n",
    "def GetKNNPredictions(k, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    t0 = time()\n",
    "    # k = 5 \n",
    "    model_px = KNeighborsClassifier(n_neighbors = k) \n",
    "\n",
    "    # fdtraining of model \n",
    "    model_px.fit(X_train, y_train) \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    t0 = time()\n",
    "    y_pred=model_px.predict(X_test)\n",
    "\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "  \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "favorite-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_embs(X, batch_size=2): #No usada desde 2024 en el código\n",
    "    norm_images = prewhiten(X)\n",
    "    pd = []\n",
    "    for start in range(0, len(norm_images), batch_size):\n",
    "        pd.append(model.predict_on_batch(norm_images[start:start+batch_size]))     #https://github.com/serengil/deepface/issues/819           \n",
    "    return l2_normalize(np.concatenate(pd))\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "\n",
    "def LoadDataset(folder, ext):\n",
    "    # Contador de número de clases del conjunto\n",
    "    nclasses = 0\n",
    "    # Contador de muestras por clase\n",
    "    nperclass = []\n",
    "    # Etiqueta de cada clase (nombre de la subcarpeta)\n",
    "    classlabels = []\n",
    "    # Inicializa estructuras de datos y sus correpondientes etiquetas\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    preprocessing = 0\n",
    "\n",
    "    # Asume que en la ruta indicada hay una subcarpeta por clase\n",
    "    for class_name in os.listdir(folder):\n",
    "        # Cada subcarpeta implica una clase más\n",
    "        nclasses += 1\n",
    "        # Inicialmente esta clase no tiene muestras\n",
    "        nsamples = 1    \n",
    "\n",
    "        # Compone la ruta\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        for file_name in os.listdir(class_folder):\n",
    "            # Asume imágenes en formato ext\n",
    "            if file_name.endswith(ext):\n",
    "                # Lee la imagen\n",
    "                image = cv2.imread (os.path.join(class_folder, file_name))  \n",
    "\n",
    "                # Obtiene embeddings\n",
    "                img1 = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                # Hasta 2023 usaba\n",
    "                # Get embeddings after preprocessing\n",
    "                #if preprocessing == 1:\n",
    "                #    img_embedding = calc_embs(np.array([img1]))\n",
    "                #else:\n",
    "                #    img_embedding = model.predict(img1[None,...])\n",
    "\n",
    "                #X.append(img_embedding[0])\n",
    "                \n",
    "                #Desde 2024\n",
    "                embedding_objs = DeepFace.represent(img_path = img1,model_name  = \"Facenet\", enforce_detection = False)   \n",
    "                img_embedding = embedding_objs[0][\"embedding\"]             \n",
    "\n",
    "                X.append(img_embedding)\n",
    "\n",
    "                # Añade etiqueta numérica de la muestra\n",
    "                Y.append(nclasses-1)\n",
    "\n",
    "                #Incrementa el número de muestras\n",
    "                nsamples += 1\n",
    "\n",
    "        nperclass.append(nsamples)\n",
    "        classlabels.append(class_name)\n",
    "\n",
    "    #Convierte a numpy array X e Y\n",
    "    X = np.array(X,dtype='float32')\n",
    "    Y = np.array(Y,dtype='float64')\n",
    "\n",
    "    # Muestra datos del conjunto leído\n",
    "    # Depuración\n",
    "    print(\"Features\")\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    # Obtiene número de muestras y características\n",
    "    n_samples , n_features = X.shape\n",
    "    # Obtiene nombres de las clases\n",
    "    class_names = np.array(classlabels)\n",
    "    n_classes = class_names.shape[0]\n",
    "    \n",
    "    return X, Y, n_samples, n_features, n_classes, classlabels, nperclass, class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-tissue",
   "metadata": {},
   "source": [
    "# Carga conjuntos de datos\n",
    "\n",
    "Se proporciona la carpeta, a través de la variable folder, donde cada subcarpeta se corresponde con una clase.\n",
    "Cada clase contiene muestras en forma de imágenes jpg, todas del mismo tamaño. Obtiene embeddings Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos disponibles ['VGG-Face', 'Facenet', 'OpenFace', 'DeepFace', 'DeepID', 'Dlib']\n",
    "model = DeepFace.build_model(\"Facenet\")\n",
    "dim = model.input_shape\n",
    "\n",
    "#MODIFICAR INDICANDO RUTA EN TU EQUIPO TRAS DESCAGAR DATOS DEL CAMPUS. EVITAR TILDES\n",
    "folder = \"C:/Users/modesto/Documents/Desarrollo/DatabaseGender59x65\" #RUTA EJEMPLO, MODIFICAR\n",
    "\n",
    "print('Loading dataset')\n",
    "X, Y, nsamples, class_name, nperclass, classlabels, width, height = LoadDataset(folder,'.jpg')\n",
    "\n",
    "#Convierte a numpy array X e Y\n",
    "X = np.array(X,dtype='float32')\n",
    "Y = np.array(Y,dtype='float64')\n",
    "\n",
    "# Obtiene número de muestras y características\n",
    "n_samples , n_features = X.shape\n",
    "# Obtiene nombres de las clases\n",
    "class_names = np.array(classlabels)\n",
    "n_classes = class_names.shape[0]\n",
    "\n",
    "print(\"Dataset info:\")\n",
    "print(\"# samples: %d\" % n_samples)\n",
    "print(\"# features: %d\" % n_features)\n",
    "print(\"# classes: %d\" % n_classes)\n",
    "print(\"classes %s\" % classlabels)\n",
    "print(\"samples per class %s\" % str(nperclass)[1:-1] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd33ba7",
   "metadata": {},
   "source": [
    "# Diseña conjunto experimental k-fold\n",
    "\n",
    "Divide los datos k veces en conjunto de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebca6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold\n",
    "# Define el número de subconjuntos a considerar\n",
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=4, shuffle=True)\n",
    "#Distribución de muestras por fold\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(\"Fold %d\" % fold)\n",
    "    print(\"# samples in training set %d\" % train_index.shape[0])\n",
    "    print(\"# samples in test set %d\" % test_index.shape[0])\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-sensitivity",
   "metadata": {},
   "source": [
    "# Lanza experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "precs_facenet_svm, recs_facenet_svm = [], []\n",
    "precs_facenet_knn, recs_facenet_knn = [], []\n",
    "\n",
    "\n",
    "# Recorre folds\n",
    "fold = 1\n",
    "while fold <= kfold:\n",
    "    accs, precs, recs = [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        print(\"***\\nFold %d\" % fold)\n",
    "        #División de muestras de entreno y test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        #Etiquetas de las muestras\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "\n",
    "        #Facenet+KNN\n",
    "        y_pred, y_test = GetKNNPredictions(11, X_train, X_test,y_train, y_test)\n",
    "        print(\"\\nFacenet+KNN Metrics\")\n",
    "        precs_facenet_knn.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recs_facenet_knn.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "        print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))      \n",
    "            \n",
    "        #Facenet+SVM\n",
    "        y_pred, y_test = GetSVMPredictions(X_train, X_test,y_train, y_test)\n",
    "        print(\"\\nFacenet+SVM Metrics\")\n",
    "        precs_facenet_svm.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recs_facenet_svm.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "        print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))        \n",
    "    \n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"Facenet+KNN Mean Precision:  %0.3f, Mean Recall:  %0.3f\" % ( np.mean(precs_facenet_knn) , np.mean(recs_facenet_knn) ))\n",
    "print(\"Facenet+SVM Mean Precision:  %0.3f, Mean Recall:  %0.3f\" % ( np.mean(precs_facenet_svm) , np.mean(recs_facenet_svm) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-accountability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
